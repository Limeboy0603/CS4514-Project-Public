{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tvb_hksl_split_parser():\n",
    "    def __init__(self, file: str):\n",
    "        self.file = file\n",
    "        self.train_info = pd.read_csv(self.file, delimiter=\"|\") \n",
    "        # extend the dataframe with extracted information\n",
    "        self.train_info[\"glosses_tokenized\"] = self.train_info[\"glosses\"].str.split(' ')\n",
    "        # self.train_info[\"date\"] = self.train_info[\"id\"].str.split('/').apply(lambda x: x[0])\n",
    "        self.train_info[\"frames\"] = self.train_info[\"id\"].str.split('/').apply(lambda x: x[1])\n",
    "        self.train_info[\"length\"] = self.train_info[\"frames\"].str.split('-').apply(lambda x: int(x[1]) - int(x[0]) + 1)\n",
    "        # add <START> and <END> tokens to the glosses\n",
    "        # self.train_info[\"glosses_tokenized\"] = self.train_info[\"glosses_tokenized\"].apply(lambda x: [\"<START>\"] + x + [\"<END>\"])\n",
    "        # self.train_info[\"glosses_length\"] = self.train_info[\"glosses_tokenized\"].apply(lambda x: len(x))\n",
    "        \n",
    "\n",
    "    def get_train_id(self) -> pd.Series:\n",
    "        if os.name == \"nt\": # for windows system only\n",
    "            return self.train_info[\"id\"].str.replace(\"/\", \"\\\\\")\n",
    "        return self.train_info[\"id\"]\n",
    "\n",
    "    def get_train_glosses_tokenized(self) -> pd.Series:\n",
    "        return self.train_info[\"glosses_tokenized\"]\n",
    "\n",
    "    def get_max_length(self) -> int:\n",
    "        return self.train_info[\"length\"].max()\n",
    "\n",
    "    # def get_max_glosses_length(self) -> int:\n",
    "    #     return self.train_info[\"glosses_length\"].max()\n",
    "\n",
    "    # def pad_train_glosses_tokenized(self, max_length: int) -> pd.Series:\n",
    "    #     self.train_info[\"glosses_tokenized\"] = self.train_info[\"glosses_tokenized\"].apply(lambda x: x + [\"<END>\"] * (max_length - len(x)))\n",
    "    #     self.train_info[\"glosses_length\"] = self.train_info[\"glosses_tokenized\"].apply(lambda x: len(x))\n",
    "    #     return self.train_info[\"glosses_tokenized\"]\n",
    "    \n",
    "    # def get_word_dict(self) -> dict:\n",
    "    #     word_dict = {}\n",
    "    #     for tokens in self.train_info[\"glosses_tokenized\"]:\n",
    "    #         for token in tokens:\n",
    "    #             if token not in word_dict:\n",
    "    #                 word_dict[token] = len(word_dict)\n",
    "    #     return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parser = tvb_hksl_split_parser(r\"F:\\dataset\\tvb-hksl-news\\split\\train.csv\")\n",
    "test_parser = tvb_hksl_split_parser(r\"F:\\dataset\\tvb-hksl-news\\split\\test.csv\")\n",
    "dev_parser = tvb_hksl_split_parser(r\"F:\\dataset\\tvb-hksl-news\\split\\dev.csv\")\n",
    "\n",
    "# make a word dictionary\n",
    "word_dict = {}\n",
    "word_dict[\"<END>\"] = len(word_dict)\n",
    "word_dict[\"<START>\"] = len(word_dict)\n",
    "word_dict[\"<X>\"] = len(word_dict)\n",
    "word_dict[\"<BAD>\"] = len(word_dict)\n",
    "word_dict[\"<MUMBLE>\"] = len(word_dict)\n",
    "word_dict[\"<STOP>\"] = len(word_dict)\n",
    "# word_dict[\"<UNK>\"] = len(word_dict)\n",
    "\n",
    "for parser in [train_parser, test_parser, dev_parser]:\n",
    "    for glosses in parser.get_train_glosses_tokenized():\n",
    "        for word in glosses:\n",
    "            if word not in word_dict:\n",
    "                word_dict[word] = len(word_dict)\n",
    "\n",
    "reverse_word_dict = {v: k for k, v in word_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_directory = r\"F:\\dataset\\tvb-hksl-news\\keypoints_mediapipe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import log_softmax\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "\n",
    "# Define the dataset class\n",
    "class SignLanguageDataset(Dataset):\n",
    "    def __init__(self, parser:tvb_hksl_split_parser, keypoint_directory, word_dict):\n",
    "        self.parser = parser\n",
    "        self.keypoint_directory = keypoint_directory\n",
    "        self.word_dict = word_dict\n",
    "        self.ids = self.parser.get_train_id()\n",
    "        self.glosses = self.parser.get_train_glosses_tokenized()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        keypoint_path = os.path.join(self.keypoint_directory, self.ids.iloc[idx] + \".npy\")\n",
    "        keypoints = np.load(keypoint_path)\n",
    "        glosses = [self.word_dict[word] for word in self.glosses.iloc[idx]]\n",
    "        return torch.tensor(keypoints, dtype=torch.float32), torch.tensor(glosses, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SignLanguageDataset(train_parser, keypoint_directory, word_dict)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolated\n",
    "\n",
    "# class SignLanguageModel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(SignLanguageModel, self).__init__()\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "#         self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x, _ = self.lstm(x)\n",
    "#         x = self.fc(x)\n",
    "#         return log_softmax(x, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous\n",
    "\n",
    "class SignLanguageModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SignLanguageModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return log_softmax(x, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "input_dim = 1662  # Number of keypoint features\n",
    "hidden_dim = 256\n",
    "output_dim = len(word_dict)\n",
    "model = SignLanguageModel(input_dim, hidden_dim, output_dim)\n",
    "criterion = CTCLoss(blank=word_dict[\"<END>\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3.3066746407469187\n",
      "Epoch 2/10, Loss: 2.822948678093062\n",
      "Epoch 3/10, Loss: 2.7538540626025916\n",
      "Epoch 4/10, Loss: 2.7410398635251747\n",
      "Epoch 5/10, Loss: 2.702391983633615\n",
      "Epoch 6/10, Loss: 2.6910918984331187\n",
      "Epoch 7/10, Loss: 2.677604852753084\n",
      "Epoch 8/10, Loss: 2.6742056435588095\n",
      "Epoch 9/10, Loss: 2.676973118801802\n",
      "Epoch 10/10, Loss: 2.6865136101613243\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        keypoints, glosses = zip(*batch)\n",
    "        keypoints = torch.nn.utils.rnn.pad_sequence(keypoints, batch_first=True)\n",
    "        glosses = torch.nn.utils.rnn.pad_sequence(glosses, batch_first=True, padding_value=word_dict[\"<END>\"])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(keypoints)\n",
    "        input_lengths = torch.full(size=(outputs.size(0),), fill_value=outputs.size(1), dtype=torch.long)\n",
    "        target_lengths = torch.tensor([len(g) for g in glosses], dtype=torch.long)\n",
    "        loss = criterion(outputs.permute(1, 0, 2), glosses, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"ctc_model_continuous.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['香港'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]\n"
     ]
    }
   ],
   "source": [
    "# Practical test\n",
    "model.eval()\n",
    "\n",
    "def predict_and_split(keypoints):\n",
    "    # predict the glosses and splitting index of each gloss in keypoints\n",
    "    keypoints = torch.tensor(keypoints, dtype=torch.float32).unsqueeze(0)\n",
    "    outputs = model(keypoints)\n",
    "    outputs = outputs.squeeze(0).detach().numpy()\n",
    "    glosses = []\n",
    "    split_indices = []\n",
    "    current_gloss = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        if output.argmax() == word_dict[\"<END>\"]:\n",
    "            glosses.append(current_gloss)\n",
    "            split_indices.append(i)\n",
    "            current_gloss = []\n",
    "        else:\n",
    "            current_gloss.append(reverse_word_dict[output.argmax()])\n",
    "    return glosses, split_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing sample: 2020-07-21/017386-017665\n",
    "# raw: D S E 文 考試 明天 說 這 四 十 百分比 入 香港 本地 全部 香港 大 七 <BAD> 考試 五 部分 五 <BAD> 星 星\n",
    "# original: 文憑試明日放榜 超過四成日校考生 考獲入讀本地大學的成績 七人考到七科5\n",
    "# interpreted: D+S+E+文+考試(=香港中學文憑考試) 明天 公佈 這 四十+百分比(=四成) 入 香港 本地 全部 香港 大 七 BAD-SEGMENT 考試 五 部份 五 BAD-SEGMENT 星 星\n",
    "\n",
    "test_keypoints = np.load(r\"F:\\dataset\\tvb-hksl-news\\keypoints_mediapipe\\2020-07-21\\017386-017665.npy\")\n",
    "test_gloss, test_split = predict_and_split(test_keypoints)\n",
    "print(test_gloss)\n",
    "print(test_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
